# -*- coding: utf-8 -*-
"""Malaya Malay Sentiment analysis.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1B9x1xHjWRRKFwgG1wY5QiTkvRqxO8Qcr

Modified from https://github.com/huseinzol05/malaya/blob/master/example/sentiment/load-sentiment.ipynb to work on Colab
"""

#install Malaya, in your virtual environment
!pip install Malaya

#probably can move up, this fixes a dependency problem in Malaya, in your virtual environment
!pip install albumentations

#probably can move up, this fixes a dependency problem in Malaya, in your virtual environment
!pip install youtokentome

#load Malaya 
import malaya

#check sentiment label - seems consistent with Panoptes
malaya.sentiment.label

string1 = 'Sis, students from overseas were brought back because they are not in their countries which is if something happens to them, its not the other countriesâ€™ responsibility. Student dalam malaysia ni dah dlm tggjawab kerajaan. Mana part yg tak faham?'
string2 = 'Harap kerajaan tak bukak serentak. Slowly release week by week. Focus on economy related industries dulu'
string3 = 'Idk if aku salah baca ke apa. Bayaran rm350 utk golongan umur 21 ke bawah shj ? Anyone? If 21 ke atas ok lah. If umur 21 ke bawah?  Are you serious? Siapa yg lebih byk komitmen? Aku hrp aku salah baca. Aku tk jumpa artikel tu'
string4 = 'Jabatan Penjara Malaysia diperuntukkan RM20 juta laksana program pembangunan Insan kepada banduan. Majikan yang menggaji bekas banduan, bekas penagih dadah diberi potongan cukai tambahan sehingga 2025.'
string5 = 'Dua Hari Nyaris Hatrick, Murai Batu Ceriwis Siap Meraikan Even Bekasi Bersatu!'
string6 = '@MasidiM Moga kerajaan sabah, tidak ikut pkp macam kerajaan pusat. Makin lama pkp, makin ramai hilang pekerjaan. Ti https://t.co/nSIABkkEDS'
string7 = 'Hopefully esok boleh ambil gambar dengan'

#classification function
def multinomial(**kwargs):
    """
    Load multinomial emotion model.

    Returns
    -------
    result : malaya.model.ml.Bayes class
    """

#create multinomial bayes classification model
model = malaya.sentiment.multinomial()

#prediction based on created model
#figure out how to read the text from excel as a list of strings
model.predict([string1, string2, string3, string4, string5, string6, string7])

#to enable List
from typing import List

#function to return predicted classes with probability 
def predict_proba(self, strings: List[str]):
    """
    classify list of strings and return probability.

    Parameters
    ----------
    strings: List[str]

    Returns
    -------
    result: List[dict[str, float]]
    """

#create a model to predict class label with probability
model.predict_proba([string1, string2, string3, string4, string5, string6, string7])

#list out transformers - mind the model size
malaya.sentiment.available_transformer()

#function to use TF models
def transformer(model: str = 'bert', quantized: bool = False, **kwargs):
    """
    Load Transformer sentiment model.

    Parameters
    ----------
    model : str, optional (default='bert')
        Model architecture supported. Allowed values:

        * ``'bert'`` - Google BERT BASE parameters.
        * ``'tiny-bert'`` - Google BERT TINY parameters.
        * ``'albert'`` - Google ALBERT BASE parameters.
        * ``'tiny-albert'`` - Google ALBERT TINY parameters.
        * ``'xlnet'`` - Google XLNET BASE parameters.
        * ``'alxlnet'`` - Malaya ALXLNET BASE parameters.
        * ``'fastformer'`` - FastFormer BASE parameters.
        * ``'tiny-fastformer'`` - FastFormer TINY parameters.

    quantized : bool, optional (default=False)
        if True, will load 8-bit quantized model.
        Quantized model not necessary faster, totally depends on the machine.

    Returns
    -------
    result: model
        List of model classes:

        * if `bert` in model, will return `malaya.model.bert.MulticlassBERT`.
        * if `xlnet` in model, will return `malaya.model.xlnet.MulticlassXLNET`.
        * if `fastformer` in model, will return `malaya.model.fastformer.MulticlassFastFormer`.
    """

#xlnet TF
model = malaya.sentiment.transformer(model = 'xlnet')

#quantized xlet
quantized_model = malaya.sentiment.transformer(model = 'xlnet', quantized = True)

#function to predict sentiment label without probabability
def predict(self, strings: List[str]):
    """
    classify list of strings.

    Parameters
    ----------
    strings: List[str]

    Returns
    -------
    result: List[str]
    """

# Commented out IPython magic to ensure Python compatibility.
# #predict string without prob
# %%time
# 
# model.predict([string1, string2, string3, string4, string5, string6, string7])

# Commented out IPython magic to ensure Python compatibility.
# #predict string using quantized model, seems slower
# %%time
# 
# quantized_model.predict([string1, string2, string3, string4, string5, string6, string7])

#setup dashboard
def predict_words(
    self,
    string: str,
    method: str = 'last',
    bins_size: float = 0.05,
    visualization: bool = True,
):
    """
    classify words.

    Parameters
    ----------
    string : str
    method : str, optional (default='last')
        Attention layer supported. Allowed values:

        * ``'last'`` - attention from last layer.
        * ``'first'`` - attention from first layer.
        * ``'mean'`` - average attentions from all layers.
    bins_size: float, optional (default=0.05)
        default bins size for word distribution histogram.
    visualization: bool, optional (default=True)
        If True, it will open the visualization dashboard.

    Returns
    -------
    dictionary: results
    """

#Takes too long
#quantized_model.predict_words(string4, bins_size = 0.01)

# Let say you want to visualize sentence / word level in lower dimension, you can use model.vectorize,
def vectorize(self, strings: List[str], method: str = 'first'):
    """
    vectorize list of strings.

    Parameters
    ----------
    strings: List[str]
    method : str, optional (default='first')
        Vectorization layer supported. Allowed values:

        * ``'last'`` - vector from last sequence.
        * ``'first'`` - vector from first sequence.
        * ``'mean'`` - average vectors from all sequences.
        * ``'word'`` - average vectors based on tokens.

    Returns
    -------
    result: np.array
    """

#vectorize at sentence level
r = quantized_model.vectorize([string1, string2, string3, string4], method = 'first')

#dimension reduction
from sklearn.manifold import TSNE
import matplotlib.pyplot as plt

tsne = TSNE().fit_transform(r)
tsne.shape

#plot sentence level sentiment
plt.figure(figsize = (7, 7))
plt.scatter(tsne[:, 0], tsne[:, 1])
labels = [string1, string2, string3, string4]
for label, x, y in zip(
    labels, tsne[:, 0], tsne[:, 1]
):
    label = (
        '%s, %.3f' % (label[0], label[1])
        if isinstance(label, list)
        else label
    )
    plt.annotate(
        label,
        xy = (x, y),
        xytext = (0, 0),
        textcoords = 'offset points',
    )

#word level
r = quantized_model.vectorize([string1, string2, string3, string4], method = 'word')

x, y = [], []
for row in r:
    x.extend([i[0] for i in row])
    y.extend([i[1] for i in row])

tsne = TSNE().fit_transform(y)
tsne.shape

#plot word level
plt.figure(figsize = (7, 7))
plt.scatter(tsne[:, 0], tsne[:, 1])
labels = x
for label, x, y in zip(
    labels, tsne[:, 0], tsne[:, 1]
):
    label = (
        '%s, %.3f' % (label[0], label[1])
        if isinstance(label, list)
        else label
    )
    plt.annotate(
        label,
        xy = (x, y),
        xytext = (0, 0),
        textcoords = 'offset points',
    )

#define two new models, bayes multinomial and TF axlnet
multinomial = malaya.sentiment.multinomial()
alxlnet = malaya.sentiment.transformer(model = 'alxlnet')

#stack the models or combine the models
malaya.stack.predict_stack([multinomial, alxlnet, model], 
                           [string1, string2, string3, string4, string5, string6, string7])